"""
DITTO å¸¦æ§åˆ¶åŠŸèƒ½çš„æ¨ç†è„šæœ¬

æ”¯æŒçš„æƒ…ç»ªï¼š0-7
- 0: Angryï¼ˆæ„¤æ€’ï¼‰
- 1: Disgustï¼ˆåŒæ¶ï¼‰
- 2: Fearï¼ˆææƒ§ï¼‰
- 3: Happyï¼ˆå¼€å¿ƒï¼‰
- 4: Neutralï¼ˆä¸­æ€§ï¼‰- é»˜è®¤
- 5: Sadï¼ˆæ‚²ä¼¤ï¼‰
- 6: Surpriseï¼ˆæƒŠè®¶ï¼‰
- 7: Contemptï¼ˆè½»è”‘ï¼‰

æ”¯æŒçš„å¤´éƒ¨å§¿æ€æ§åˆ¶ï¼š
- delta_pitch: ä¿¯ä»°è§’åç§»ï¼ˆåº¦ï¼Œæ­£æ•°å‘ä¸Šï¼Œè´Ÿæ•°å‘ä¸‹ï¼‰
- delta_yaw: åèˆªè§’åç§»ï¼ˆåº¦ï¼Œæ­£æ•°å‘å³ï¼Œè´Ÿæ•°å‘å·¦ï¼‰
- delta_roll: ç¿»æ»šè§’åç§»ï¼ˆåº¦ï¼Œæ­£æ•°å‘å³å€¾æ–œï¼Œè´Ÿæ•°å‘å·¦å€¾æ–œï¼‰
"""

import librosa
import math
import os
import numpy as np
import pickle
from stream_pipeline_offline import StreamSDK


def create_control_config(emotion=4, head_movements=None, fade_in=10, fade_out=10):
    """
    åˆ›å»ºæ§åˆ¶é…ç½®
    
    Args:
        emotion: æƒ…ç»ªæ ‡ç­¾æˆ–æƒ…ç»ªåºåˆ—
            - int: å•ä¸€æƒ…ç»ªï¼ˆ0-7ï¼‰
            - list[int]: æ··åˆæƒ…ç»ªï¼Œå¦‚ [3, 4]
            - list[list[int]]: æ¯å¸§çš„æƒ…ç»ªåºåˆ—ï¼Œå¦‚ [[3], [3, 4], [4], ...]
        head_movements: å¤´éƒ¨è¿åŠ¨æ§åˆ¶å­—å…¸
            {
                frame_idx: {
                    "delta_pitch": float,  # ä¿¯ä»°è§’åç§»ï¼ˆåº¦ï¼‰
                    "delta_yaw": float,    # åèˆªè§’åç§»ï¼ˆåº¦ï¼‰
                    "delta_roll": float,   # ç¿»æ»šè§’åç§»ï¼ˆåº¦ï¼‰
                }
            }
        fade_in: æ·¡å…¥å¸§æ•°
        fade_out: æ·¡å‡ºå¸§æ•°
    
    Returns:
        dict: æ§åˆ¶é…ç½®
    """
    control_config = {
        "setup_kwargs": {
            "emo": emotion,
        },
        "run_kwargs": {
            "fade_in": fade_in,
            "fade_out": fade_out,
            "ctrl_info": head_movements or {},
        }
    }
    return control_config


def run_with_control(SDK, audio_path, source_path, output_path, control_config=None):
    """
    ä½¿ç”¨æ§åˆ¶é…ç½®è¿è¡Œæ¨ç†
    
    Args:
        SDK: StreamSDK å®ä¾‹
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        source_path: æºå›¾åƒ/è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        control_config: æ§åˆ¶é…ç½®å­—å…¸
    """
    if control_config is None:
        control_config = create_control_config()
    
    setup_kwargs = control_config.get("setup_kwargs", {})
    run_kwargs = control_config.get("run_kwargs", {})
    
    # è®¾ç½®
    SDK.setup(source_path, output_path, **setup_kwargs)
    
    # åŠ è½½éŸ³é¢‘å¹¶è®¡ç®—å¸§æ•°
    audio, sr = librosa.core.load(audio_path, sr=16000)
    num_f = math.ceil(len(audio) / 16000 * 25)
    
    # è®¾ç½®æ§åˆ¶å‚æ•°
    fade_in = run_kwargs.get("fade_in", -1)
    fade_out = run_kwargs.get("fade_out", -1)
    ctrl_info = run_kwargs.get("ctrl_info", {})
    
    SDK.setup_Nd(N_d=num_f, fade_in=fade_in, fade_out=fade_out, ctrl_info=ctrl_info)
    
    # è¿è¡Œæ¨ç†
    online_mode = SDK.online_mode
    if online_mode:
        chunksize = run_kwargs.get("chunksize", (3, 5, 2))
        audio = np.concatenate([np.zeros((chunksize[0] * 640,), dtype=np.float32), audio], 0)
        split_len = int(sum(chunksize) * 0.04 * 16000) + 80
        for i in range(0, len(audio), chunksize[1] * 640):
            audio_chunk = audio[i:i + split_len]
            if len(audio_chunk) < split_len:
                audio_chunk = np.pad(audio_chunk, (0, split_len - len(audio_chunk)), mode="constant")
            SDK.run_chunk(audio_chunk, chunksize)
    else:
        aud_feat = SDK.wav2feat.wav2feat(audio)
        SDK.audio2motion_queue.put(aud_feat)
    
    SDK.close()
    
    # åˆå¹¶éŸ³é¢‘
    cmd = f'ffmpeg -loglevel error -y -i "{SDK.tmp_output_path}" -i "{audio_path}" -map 0:v -map 1:a -c:v copy -c:a aac "{output_path}"'
    print(f"æ‰§è¡Œ: {cmd}")
    os.system(cmd)
    
    print(f"âœ… è¾“å‡ºè§†é¢‘: {output_path}")


def create_natural_head_movement(num_frames, interval=30):
    """
    åˆ›å»ºè‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨åºåˆ—
    
    Args:
        num_frames: æ€»å¸§æ•°
        interval: å¤´éƒ¨åŠ¨ä½œé—´éš”ï¼ˆå¸§ï¼‰
    
    Returns:
        dict: å¤´éƒ¨è¿åŠ¨æ§åˆ¶å­—å…¸
    """
    head_movements = {}
    
    for i in range(0, num_frames, interval):
        # éšæœºé€‰æ‹©å¤´éƒ¨åŠ¨ä½œ
        action = np.random.choice(["left", "right", "up", "down", "center"])
        
        if action == "left":
            head_movements[i] = {"delta_yaw": -10.0 + np.random.uniform(-3, 3)}
        elif action == "right":
            head_movements[i] = {"delta_yaw": 10.0 + np.random.uniform(-3, 3)}
        elif action == "up":
            head_movements[i] = {"delta_pitch": 5.0 + np.random.uniform(-2, 2)}
        elif action == "down":
            head_movements[i] = {"delta_pitch": -5.0 + np.random.uniform(-2, 2)}
        else:  # center
            head_movements[i] = {"delta_yaw": 0.0, "delta_pitch": 0.0}
        
        # ä¸‹ä¸€å¸§æ¢å¤
        if i + 10 < num_frames:
            head_movements[i + 10] = {"delta_yaw": 0.0, "delta_pitch": 0.0}
    
    return head_movements


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="DITTO å¸¦æ§åˆ¶åŠŸèƒ½çš„æ¨ç†è„šæœ¬")
    parser.add_argument("--data_root", type=str, default="./checkpoints/ditto_trt_Ampere_Plus",
                        help="æ¨¡å‹æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--cfg_pkl", type=str, default="./checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl",
                        help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--audio_path", type=str, required=True,
                        help="è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--source_path", type=str, required=True,
                        help="è¾“å…¥å›¾åƒ/è§†é¢‘è·¯å¾„")
    parser.add_argument("--output_path", type=str, required=True,
                        help="è¾“å‡ºè§†é¢‘è·¯å¾„")
    
    # æƒ…ç»ªæ§åˆ¶
    parser.add_argument("--emotion", type=int, default=4,
                        help="æƒ…ç»ªæ ‡ç­¾ (0:Angry, 1:Disgust, 2:Fear, 3:Happy, 4:Neutral, 5:Sad, 6:Surprise, 7:Contempt)")
    
    # å¤´éƒ¨å§¿æ€æ§åˆ¶
    parser.add_argument("--head_yaw", type=float, default=None,
                        help="å¤´éƒ¨åèˆªè§’åç§»ï¼ˆåº¦ï¼Œæ­£æ•°å‘å³ï¼Œè´Ÿæ•°å‘å·¦ï¼‰")
    parser.add_argument("--head_pitch", type=float, default=None,
                        help="å¤´éƒ¨ä¿¯ä»°è§’åç§»ï¼ˆåº¦ï¼Œæ­£æ•°å‘ä¸Šï¼Œè´Ÿæ•°å‘ä¸‹ï¼‰")
    parser.add_argument("--head_roll", type=float, default=None,
                        help="å¤´éƒ¨ç¿»æ»šè§’åç§»ï¼ˆåº¦ï¼‰")
    parser.add_argument("--control_frame", type=int, default=0,
                        help="åº”ç”¨å¤´éƒ¨æ§åˆ¶çš„å¸§ç´¢å¼•")
    
    # è‡ªåŠ¨å¤´éƒ¨è¿åŠ¨
    parser.add_argument("--auto_head_movement", action="store_true",
                        help="å¯ç”¨è‡ªåŠ¨å¤´éƒ¨è¿åŠ¨ï¼ˆè‡ªç„¶çš„å¤´éƒ¨æ‘†åŠ¨ï¼‰")
    
    # æ·¡å…¥æ·¡å‡º
    parser.add_argument("--fade_in", type=int, default=10,
                        help="æ·¡å…¥å¸§æ•°")
    parser.add_argument("--fade_out", type=int, default=10,
                        help="æ·¡å‡ºå¸§æ•°")
    
    # æ§åˆ¶é…ç½®æ–‡ä»¶
    parser.add_argument("--control_config", type=str, default=None,
                        help="æ§åˆ¶é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆ.pkl æ ¼å¼ï¼‰")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ– SDK
    SDK = StreamSDK(args.cfg_pkl, args.data_root)
    
    # å‡†å¤‡æ§åˆ¶é…ç½®
    if args.control_config:
        # ä»æ–‡ä»¶åŠ è½½
        print(f"ğŸ“ ä»æ–‡ä»¶åŠ è½½æ§åˆ¶é…ç½®: {args.control_config}")
        with open(args.control_config, "rb") as f:
            control_config = pickle.load(f)
    else:
        # ä»å‘½ä»¤è¡Œå‚æ•°åˆ›å»º
        head_movements = None
        
        # è‡ªåŠ¨å¤´éƒ¨è¿åŠ¨
        if args.auto_head_movement:
            audio, sr = librosa.core.load(args.audio_path, sr=16000)
            num_frames = math.ceil(len(audio) / 16000 * 25)
            head_movements = create_natural_head_movement(num_frames)
            print(f"ğŸ¬ å¯ç”¨è‡ªåŠ¨å¤´éƒ¨è¿åŠ¨ï¼Œå…± {len(head_movements)} ä¸ªæ§åˆ¶ç‚¹")
        
        # æ‰‹åŠ¨å¤´éƒ¨æ§åˆ¶
        elif any([args.head_yaw, args.head_pitch, args.head_roll]):
            head_movements = {
                args.control_frame: {}
            }
            if args.head_yaw is not None:
                head_movements[args.control_frame]["delta_yaw"] = args.head_yaw
                print(f"â†”ï¸  è®¾ç½®åèˆªè§’: {args.head_yaw}Â° (å¸§ {args.control_frame})")
            if args.head_pitch is not None:
                head_movements[args.control_frame]["delta_pitch"] = args.head_pitch
                print(f"â†•ï¸  è®¾ç½®ä¿¯ä»°è§’: {args.head_pitch}Â° (å¸§ {args.control_frame})")
            if args.head_roll is not None:
                head_movements[args.control_frame]["delta_roll"] = args.head_roll
                print(f"â†»  è®¾ç½®ç¿»æ»šè§’: {args.head_roll}Â° (å¸§ {args.control_frame})")
        
        # æƒ…ç»ªæ ‡ç­¾è¯´æ˜
        emotion_names = ["Angry", "Disgust", "Fear", "Happy", "Neutral", "Sad", "Surprise", "Contempt"]
        print(f"ğŸ˜Š è®¾ç½®æƒ…ç»ª: {emotion_names[args.emotion]} ({args.emotion})")
        
        control_config = create_control_config(
            emotion=args.emotion,
            head_movements=head_movements,
            fade_in=args.fade_in,
            fade_out=args.fade_out
        )
    
    # è¿è¡Œæ¨ç†
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆè§†é¢‘...")
    print(f"   éŸ³é¢‘: {args.audio_path}")
    print(f"   å›¾åƒ: {args.source_path}")
    print(f"   è¾“å‡º: {args.output_path}")
    
    run_with_control(SDK, args.audio_path, args.source_path, args.output_path, control_config)
    
    print("âœ… å®Œæˆï¼")

